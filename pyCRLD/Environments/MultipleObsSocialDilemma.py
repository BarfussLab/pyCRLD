# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/Environments/12_MultipleObsSocialDilemma.ipynb.

# %% auto 0
__all__ = ['MultipleObsSocialDilemma']

# %% ../../nbs/Environments/12_MultipleObsSocialDilemma.ipynb 6
from .Base import ebase

from fastcore.utils import *
from fastcore.test import *

from .HeterogeneousObservationsEnv import HeterogeneousObservationsEnv

import numpy as np

# %% ../../nbs/Environments/12_MultipleObsSocialDilemma.ipynb 7
class MultipleObsSocialDilemma(HeterogeneousObservationsEnv):
    """
    Symmetric 2-agent 2-action Social Dilemma Matrix Game.
    """
    def __init__(self,
                 rewards, # reward of mutual cooperation
                 temptations, # temptation of unilateral defection
                 suckers_payoffs, # sucker's payoff of unilateral cooperation
                 punishments, # punishment of mutual defection
                 contract_probability = 0.5, # probability for contract
                 observation_type='default', # type of observability matrix
                 observation_value=None): # partial or full observability

        # Validate each attribute to ensure it is either an integer or a list of two integers
        def validate_attribute(attribute):
            if isinstance(attribute, list) and len(attribute) == 2:
                return attribute
            elif isinstance(attribute, (int, float, complex)):
                return [attribute]
            else:
                raise ValueError("Attribute must be a single integer or a list of two integers.")
        
        # Applying the validation to each attribute
        self.rewards = validate_attribute(rewards)
        self.temptations = validate_attribute(temptations)
        self.suckers_payoffs = validate_attribute(suckers_payoffs)
        self.punishments = validate_attribute(punishments)

        # TODO: these variables are expected to be already initialized in the parent class
        # causing a recursive calling and causing the dependency on them to fail
        # therefore we need to initialize them here. In the future this should be addressed
        self.n_agents = 2
        self.n_agent_actions = 2
        self.n_states = len(self.rewards)
        
        # The contract_probability adds a dynamic aspect to the game where the outcome can also depend on the evolving 
        # relationship state (contract or no contract).
        # A state can be either contracted or not, or have the default state '.'. The contract indicate whether
        # there is an agreement or alignment between the agents, which could influence their strategic decisions.
        self.contract_probability = contract_probability
        self.state = 0 # initial state

        super().__init__(observation_type=observation_type, observation_value=observation_value)

# %% ../../nbs/Environments/12_MultipleObsSocialDilemma.ipynb 8
@patch
def transition_tensor(self:MultipleObsSocialDilemma):
    """Calculate the Transition Tensor"""
    if self.n_states == 1:
        Tsas = np.ones((self.n_states, self.n_agent_actions, self.n_agent_actions, self.n_states))
    # Case for contract/no-contract states
    else:
        Tsas = np.ones((self.n_states, self.n_agent_actions, self.n_agent_actions, self.n_states)) * (-1)
        Tsas[:, :, :, 0] = 1 - self.contract_probability
        Tsas[:, :, :, 1] = self.contract_probability
    return Tsas

@patch
def reward_tensor(self:MultipleObsSocialDilemma):
    """Get the Reward Tensor R[i,s,a1,...,aN,s']."""

    R = np.zeros((self.n_agents, self.n_states, self.n_agent_actions, self.n_agent_actions, self.n_states))

    if self.n_states == 1:
        R[0, 0, :, :, 0] = [[self.rewards[0], self.suckers_payoffs[0]],
                            [self.temptations[0], self.punishments[0]]]
        R[1, 0, :, :, 0] = [[self.rewards[0], self.temptations[0]],
                            [self.suckers_payoffs[0], self.punishments[0]]]
    else:
        # set reward matrix for agents in first (no-contract) state
        R[0, 0, :, :, 0] = [[self.rewards[0], self.suckers_payoffs[0]],
                            [self.temptations[0], self.punishments[0]]]
        R[1, 0, :, :, 0] = [[self.rewards[0], self.temptations[0]],
                            [self.suckers_payoffs[0], self.punishments[0]]]
        R[:, 0, :, :, 1] = R[:, 0, :, :, 0]
    
        # set reward matrix for agents the second (contract) state
        R[0, 1, :, :, 1] = [[self.rewards[1], self.suckers_payoffs[1]],
                            [self.temptations[1], self.punishments[1]]]
        R[1, 1, :, :, 1] = [[self.rewards[1], self.temptations[1]],
                            [self.suckers_payoffs[1], self.punishments[1]]]
        R[:, 1, :, :, 0] = R[:, 1, :, :, 1]
        
    return R


@patch
def actions(self:MultipleObsSocialDilemma):
    """The action sets"""
    return [['c', 'd'] for _ in range(self.n_agents)]

@patch
def states(self:MultipleObsSocialDilemma):
    """The states set"""
    # Check whether the game has 2 rewards, this is equivalent of checking any of the
    # other game values and equivalent to checking if the number of states should be 2
    if self.n_states == 2:
        return [0, 1], ["no contract", "contract"]
    # Otherwise we default to the unique IPD state
    else:
        return ['.']

@patch
def id(self:MultipleObsSocialDilemma):
    """
    Returns id string of environment
    """
    # Default
    id = f"{self.__class__.__name__}_"+\
        f"{self.temptations}_{self.rewards}_{self.punishments}_{self.suckers_payoffs}"
    return id
