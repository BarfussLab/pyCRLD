{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da35e275-00e5-48fa-84f2-7f0721804e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Environments/HeterogeneousObservationsEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f44aea3-a46f-4db1-8ec3-0780e679ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Imports for the nbdev development environment\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de765b1-fae2-4d63-b275-deb7de1ad4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42dfe465-c409-4fcf-b40a-0c27724dd8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd103bb1-50f6-469d-a073-617a3dcd0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HeterogeneousObservationsEnv(object):\n",
    "    def __init__(self, observation_opacity):\n",
    "\n",
    "        self.observation_opacity = observation_opacity\n",
    "\n",
    "        self.transitions = self.transition_tensor()\n",
    "        self.final_states = np.array(self.generate_final_states())\n",
    "        self.rewards = self.reward_tensor()\n",
    "        self.observations = self.generate_observation_tensor()\n",
    "\n",
    "        self.actions_set = self.actions()\n",
    "        self.states_set = self.states() \n",
    "        self.observation_labels = self.generate_observation_labels()\n",
    "        # R, T, O = self.rewards, self.transitions, self.observations\n",
    "\n",
    "        self.n_agents = self.rewards.shape[0]\n",
    "        self.n_states = self.transitions.shape[0]\n",
    "        self.n_agent_actions = self.transitions.shape[1]\n",
    "\n",
    "        # assert len(self.observation_opacity) == self.n_agents, 'Observation confidences need to be specified for all agents'\n",
    "\n",
    "        # Checks\n",
    "        # assert all(self.transitions.shape[1:-1] == self.n_agent_actions for _ in range(self.n_agents)), 'Inconsistent number of actions'\n",
    "        assert all(dim == self.n_agent_actions for dim in self.rewards.shape[2:-1]), 'Inconsistent number of actions'\n",
    "        assert len(self.actions_set) == self.n_agents and all(len(a) == self.n_agent_actions for a in self.actions_set), 'Inconsistent number of actions'\n",
    "        assert self.transitions.shape[-1] == self.n_states and self.rewards.shape[-1] == self.n_states, 'Inconsistent number of states'\n",
    "        assert self.rewards.shape[1] == self.n_states, 'Inconsistent number of states'\n",
    "        assert len(self.final_states) == self.n_states, 'Inconsistent number of states'\n",
    "        assert len(self.states_set) == self.n_states, 'Inconsistent number of states'\n",
    "        assert np.allclose(self.transitions.sum(-1), 1), 'Transition model probabilities do not sum to 1'\n",
    "\n",
    "        #     assert obs.shape[0] == self.n_agents, \"Inconsistent number of agents\"\n",
    "        #     assert obs.shape[1] == self.n_states, \"Inconsistent number of states\"\n",
    "        #     assert np.allclose(obs.sum(-1), 1), 'Observation model probabilities do not sum to 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc0a4ef-1c5c-424e-87bc-8b32930be2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def id(self:HeterogeneousObservationsEnv):\n",
    "    \"\"\"Returns id string of environment\"\"\"\n",
    "    return f\"{self.__class__.__name__}\"\n",
    "\n",
    "@patch\n",
    "def __str__(self:HeterogeneousObservationsEnv): return self.id()\n",
    "\n",
    "@patch\n",
    "def __repr__(self:HeterogeneousObservationsEnv): return self.id()\n",
    "\n",
    "@patch\n",
    "def transition_tensor(self:HeterogeneousObservationsEnv):\n",
    "    raise NotImplementedError\n",
    "@patch\n",
    "def reward_tensor(self:HeterogeneousObservationsEnv):\n",
    "    raise NotImplementedError\n",
    "\n",
    "@patch\n",
    "def generate_observation_tensor(self:HeterogeneousObservationsEnv):\n",
    "    \"\"\"\n",
    "    Generates the observation tensor for the environment. The tensor represents the probability distribution over possible\n",
    "    observations given the actual state of the environment. The configuration of the tensor is influenced by the observation\n",
    "    confidence of each agent, which is now a list of floats, with each float indicating the confidence level of the corresponding\n",
    "    agent.\n",
    "    \"\"\"\n",
    "    self.n_observations = self.n_states\n",
    "    \n",
    "    # if np.all(np.array(self.observation_opacity) > 0.5):\n",
    "    #     self.n_observations = 1\n",
    "    #     observations_iso = np.ones((self.n_agents, self.n_states, self.n_observations))\n",
    "    # else:\n",
    "    # Otherwise, set the number of observations equal to the number of states,\n",
    "    # indicating a more detailed observation model.\n",
    "    observations_iso = np.zeros((self.n_agents, self.n_states, self.n_observations))\n",
    "\n",
    "    for agent_index in range(self.n_agents):\n",
    "        print('for agent ', agent_index)\n",
    "        # For each agent, configure the observation probabilities based on their individual observation confidence.\n",
    "        # Adjust the observation tensor accordingly. The following assumes a binary state space for simplicity.\n",
    "        # This logic may need to be extended for environments with more than two states.\n",
    "        confidence = self.observation_opacity[agent_index]\n",
    "        print('confidence is ,', confidence)\n",
    "        print(self.n_agents, self.n_states, self.n_observations)\n",
    "        # observations_iso = np.zeros((self.n_agents, self.n_states, self.n_observations))\n",
    "        # print(f'observations_iso[{agent_index}, 0, 0] {1 - min(confidence, 0.5)}')\n",
    "        # print(f'observations_iso[{agent_index}, 0, 1] {0 + min(confidence, 0.5)}')\n",
    "        # print(f'observations_iso[{agent_index}, 1, 0] {0 + min(confidence, 0.5)}')\n",
    "        # print(f'observations_iso[{agent_index}, 1, 1] {1 - min(confidence, 0.5)}')\n",
    "        observations_iso[agent_index, 0, 0] = 1 - min(confidence, 0.5)\n",
    "        observations_iso[agent_index, 0, 1] = 0 + min(confidence, 0.5)\n",
    "        observations_iso[agent_index, 1, 0] = 0 + min(confidence, 0.5)\n",
    "        observations_iso[agent_index, 1, 1] = 1 - min(confidence, 0.5)\n",
    "    \n",
    "    return observations_iso\n",
    "\n",
    "# #| export\n",
    "# @patch\n",
    "# def ObservationTensor(self:UncertainSocialDilemma):\n",
    "\n",
    "#         if np.all(self.noise > 0.5):\n",
    "#             self.Q = 1\n",
    "#             Oiso = np.ones((self.N, self.Z, self.Q))\n",
    "            \n",
    "#         else:\n",
    "#             self.Q = self.Z\n",
    "#             print((self.N, self.Z, self.Q))\n",
    "#             print('==========================')\n",
    "#             Oiso = np.zeros((self.N, self.Z, self.Q))\n",
    "\n",
    "#             for i in range(self.N):\n",
    "#                 Oiso[i,0,0] = 1 - min(self.noise[i], 0.5)\n",
    "#                 Oiso[i,0,1] = 0 + min(self.noise[i], 0.5)\n",
    "#                 Oiso[i,1,0] = 0 + min(self.noise[i], 0.5)\n",
    "#                 Oiso[i,1,1] = 1 - min(self.noise[i], 0.5)\n",
    "            \n",
    "#         return Oiso\n",
    "\n",
    "\n",
    "\n",
    "@patch\n",
    "def generate_final_states(self:HeterogeneousObservationsEnv):\n",
    "    \"\"\"Default final states: no final states\"\"\"\n",
    "    return np.zeros(self.n_states, dtype=int)\n",
    "\n",
    "@patch\n",
    "def actions(self:HeterogeneousObservationsEnv):\n",
    "    \"\"\"Default action set representations.\"\"\"\n",
    "    return [[str(a) for a in range(self.n_agent_actions)] for _ in range(self.n_agents)]\n",
    "\n",
    "@patch\n",
    "def states(self:HeterogeneousObservationsEnv):\n",
    "    \"\"\"Default state set representation.\"\"\"\n",
    "    return [str(s) for s in range(self.n_states)]\n",
    "\n",
    "@patch\n",
    "def generate_observation_labels(self:HeterogeneousObservationsEnv):\n",
    "    \"\"\"Creates observation labels.\"\"\"\n",
    "    return [[str(o) for o in range(self.n_observations)] for _ in range(self.n_agents)]\n",
    "\n",
    "@patch\n",
    "def step(self:HeterogeneousObservationsEnv, jA:Iterable) -> tuple:\n",
    "    \"\"\"Iterate the environment one step forward.\"\"\"\n",
    "    tps = self.transitions[tuple([self.state]+list(jA))].astype(float)\n",
    "    next_state = np.random.choice(range(len(tps)), p=tps)\n",
    "    rewards = self.rewards[tuple([slice(self.n_agents), self.state]+list(jA)+[next_state])]\n",
    "    self.state = next_state\n",
    "    obs = self.generate_stochastic_observations()\n",
    "    done = self.state in np.where(self.final_states==1)[0]\n",
    "    info = {'state': self.state}\n",
    "    return obs, rewards.astype(float), done, info\n",
    "\n",
    "@patch\n",
    "def generate_stochastic_observations(self:HeterogeneousObservationsEnv) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Produces a set of observations for each agent based on the current state, utilizing the defined observation tensors.\n",
    "    Each tensor represents a different observation model, and this method generates observations according to the probability\n",
    "    distributions specified in those tensors for the current state.\n",
    "    \n",
    "    Returns:\n",
    "        A list of numpy arrays, where each array contains observations for all agents as determined by one of the observation tensors.\n",
    "    \"\"\"\n",
    "    all_agents_observations = []  # Stores observations generated by each observation tensor.\n",
    "    for observation_tensor in self.observations_list:\n",
    "        current_state_observations = np.zeros(self.n_agents, dtype=int)  # Initializes the observation array for this tensor.\n",
    "        for agent_index in range(self.n_agents):\n",
    "            # Retrieves the probability distribution of observations for the current agent and state from the tensor.\n",
    "            observation_probabilities = observation_tensor[agent_index, self.state]\n",
    "            # Generates a random observation based on the probability distribution.\n",
    "            chosen_observation = np.random.choice(range(len(observation_probabilities)), p=observation_probabilities)\n",
    "            current_state_observations[agent_index] = chosen_observation\n",
    "        all_agents_observations.append(current_state_observations)\n",
    "    return all_agents_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88f0ba2-efc5-4c18-9bc9-0d9c8a253f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6da2a-fc80-487e-8049-e6040737ff30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bec65f-7656-46d3-9bfa-c0aa497dfd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d9ecc-fcb8-4f64-bf06-c51af188f70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
