{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6ff638-4711-4c3e-953e-f0fa7e76a6a4",
   "metadata": {},
   "source": [
    "# Uncertain Social Dilemma\n",
    "\n",
    "> Class for two states social dilemma with partial observing agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0d896-4f09-4abc-9b1c-4d2d559b5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Environments/UncertainSocialDilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06c9b1-0d04-478c-b6fc-9b88643afeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Imports for the nbdev development environment\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be651fb-f4d7-4a44-b769-34c81115a3e4",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4c230-e82b-4eee-86fa-ec422c5d340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyCRLD.Environments.UncertainSocialDilemma import UncertainSocialDilemma\n",
    "from pyCRLD.Environments.SocialDilemma import SocialDilemma\n",
    "from pyCRLD.Agents.POStrategyActorCritic import POstratAC\n",
    "from pyCRLD.Agents.StrategyActorCritic import stratAC\n",
    "\n",
    "from pyCRLD.Utils import FlowPlot as fp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdcf041-e0cb-455b-81ae-dd981017a3ea",
   "metadata": {},
   "source": [
    "### Full observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396cd2b-859c-4ef4-b8fb-5b511ba9bb1b",
   "metadata": {},
   "source": [
    "An example for a two states Prisonners Dilemma, first without observation noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646df7d-29cc-45e8-a4fb-756035779db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_fullObs = UncertainSocialDilemma(R1=5, T1=6, S1=-1, P1=0, R2=5, T2=2, S2=-1, P2=0, pC=0.5, obsnoise=0)\n",
    "mae_fullObs = POstratAC(env=env_fullObs, learning_rates=0.1, discount_factors=0.9)\n",
    "pc00, pc01, pc10, pc11 = 0.35, 0.35, 0.8, 0.8\n",
    "X = [[[pc00, 1-pc00],     #initial policy to visulize learning trajectory\n",
    "      [pc01, 1-pc01]], \n",
    "     [[pc10, 1-pc10], \n",
    "      [pc11, 1-pc11]]] \n",
    "X = np.array(X)\n",
    "xtraj, fixedpointreached = mae_fullObs.trajectory(X)\n",
    "\n",
    "x = ([0], [0,1], [0])  # Plotting on the x-axis the [0]'s agents probability in both observations [0,1] to cooprate [0]\n",
    "y = ([1], [0,1], [0])  # Plotting on the y-axis the [1]'s agents probability in both observations [0,1] to cooprate [0]\n",
    "ax = fp.plot_strategy_flow(mae_fullObs, x, y, flowarrow_points = np.linspace(0.01 ,0.99, 9), NrRandom=16)\n",
    "fp.plot_trajectories([xtraj], x, y, cols=['purple'], axes=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246f5b4-93d0-4eea-a0ee-65c9fa58ca87",
   "metadata": {},
   "source": [
    "In state 0 both agents learn to defect. In state 1 they learn to cooperate if their initial cooperation prpability is not to low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee89e3a-e4bc-440a-bd45-717650dc22a3",
   "metadata": {},
   "source": [
    "If we use the stratAC class instead of the POstratAC class, nothing changes because there is no observation noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f2974-7b7d-4138-b000-4e73ed03fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_fullObs_strat = stratAC(env=env_fullObs, learning_rates=0.1, discount_factors=0.9)\n",
    "xtraj, fixedpointreached = mae_fullObs_strat.trajectory(X)\n",
    "\n",
    "ax = fp.plot_strategy_flow(mae_fullObs_strat, x, y, flowarrow_points = np.linspace(0.01 ,0.99, 9), NrRandom=16)\n",
    "fp.plot_trajectories([xtraj], x, y, cols=['purple'], axes=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95eb7aa-723a-4ca5-9a51-0e1ee840348a",
   "metadata": {},
   "source": [
    "### Random observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53f699-c0b9-4251-b0f6-6dc2ac706d08",
   "metadata": {},
   "source": [
    "What happens when in each state the agents think they are in the true or in the other state with the same propability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809acdb-6c49-48dd-9501-5002c2255d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_randObs = UncertainSocialDilemma(R1=5, T1=6, S1=-1, P1=0, R2=5, T2=2, S2=-1, P2=0, pC=0.5, obsnoise=0.5)\n",
    "mae_randObs = POstratAC(env=env_randObs, learning_rates=0.1, discount_factors=0.9)\n",
    "xtraj, fixedpointreached = mae_randObs.trajectory(X)\n",
    "\n",
    "ax = fp.plot_strategy_flow(mae_randObs, x, y, flowarrow_points = np.linspace(0.01 ,0.99, 9), NrRandom=16)\n",
    "fp.plot_trajectories([xtraj], x, y, cols=['purple'], axes=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83354d56-426d-45a2-84e9-207e3a0ed5af",
   "metadata": {},
   "source": [
    "The learning trajectories in both states are the same. In both states the agents can learn to defect or to cooperate, depending on the inital policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63fcbf3-8c58-494c-a37a-3867fc8286ca",
   "metadata": {},
   "source": [
    "### Uncertain observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f46e2d-006e-4f62-88ba-e906f9351807",
   "metadata": {},
   "source": [
    "How does a high observation noise of 0.45 (hence the it is still more probable to observe the true state) influence the learning dynamics compared to a low observation noise of 0.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1121b9-2425-4fde-8eba-6eefd7a78f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_bituncertObs = UncertainSocialDilemma(R1=5, T1=6, S1=-1, P1=0, R2=5, T2=2, S2=-1, P2=0, pC=0.5, obsnoise=0.2)\n",
    "mae_bituncertObs = POstratAC(env=env_bituncertObs, learning_rates=0.1, discount_factors=0.9)\n",
    "xtraj, fixedpointreached = mae_bituncertObs.trajectory(X)\n",
    "\n",
    "ax = fp.plot_strategy_flow(mae_bituncertObs, x, y, flowarrow_points = np.linspace(0.01 ,0.99, 9), NrRandom=16)\n",
    "fp.plot_trajectories([xtraj], x, y, cols=['purple'], axes=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9d62c-1e23-42a4-9814-b1e2fcde1018",
   "metadata": {},
   "source": [
    "For a low noise the dynamics are close the the dynamics for full observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87819e82-630a-49b8-a7e9-759fe40a4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_veryuncertObs = UncertainSocialDilemma(R1=5, T1=6, S1=-1, P1=0, R2=5, T2=2, S2=-1, P2=0, pC=0.5, obsnoise=0.45)\n",
    "mae_veryuncertObs = POstratAC(env=env_veryuncertObs, learning_rates=0.1, discount_factors=0.9)\n",
    "xtraj, fixedpointreached = mae_veryuncertObs.trajectory(X)\n",
    "\n",
    "ax = fp.plot_strategy_flow(mae_veryuncertObs, x, y, flowarrow_points = np.linspace(0.01 ,0.99, 9), NrRandom=16)\n",
    "fp.plot_trajectories([xtraj], x, y, cols=['purple'], axes=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0fb48-8c4e-4c88-b865-fffde893f718",
   "metadata": {},
   "source": [
    "Only for relatively high noise we clearly see its influence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7ef6a-fdc7-43d3-b44f-bf2e3ab11e32",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9674b5b-dcf3-456a-815a-393a652156e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pyCRLD.Environments.Base import ebase\n",
    "from pyCRLD.Utils.Helpers import make_variable_vector\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from typing import Iterable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3696528-7c80-428e-aa0d-8fa3f176603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UncertainSocialDilemma(ebase):\n",
    "\n",
    "    def __init__(self, R1, T1, S1, P1, R2, T2, S2, P2, pC, obsnoise):\n",
    "        self.N = 2\n",
    "        self.M = 2\n",
    "        self.Z = 2\n",
    "\n",
    "        self.R1 = R1\n",
    "        self.T1 = T1\n",
    "        self.S1 = S1    \n",
    "        self.P1 = P1    \n",
    "\n",
    "        self.R2 = R2\n",
    "        self.T2 = T2\n",
    "        self.S2 = S2    \n",
    "        self.P2 = P2    \n",
    "        \n",
    "        self.pC = pC  # prop. contract\n",
    "        if not hasattr(obsnoise, \"__iter__\"):\n",
    "            self.noise = np.array([obsnoise, obsnoise])\n",
    "        else:\n",
    "            assert len(obsnoise) == 2\n",
    "            self.obsnoise = np.array(obsnoise)\n",
    "        assert min(self.noise) >= 0.0\n",
    "\n",
    "        # --\n",
    "        self.T = self.TransitionTensor()\n",
    "        self.R = self.RewardTensor()\n",
    "        self.O = self.ObservationTensor()\n",
    "        self.state = 1 # inital state\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5d75f-885b-45dd-8484-9d13719c23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def actions(self:UncertainSocialDilemma):\n",
    "        return [0, 1], [\"coop.\", \"defect.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d627ac-1ec4-4d6e-a37d-53faecc0b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def states(self:UncertainSocialDilemma):\n",
    "        return [0, 1], [\"no contract\", \"contract\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca1842-f37b-411c-9d4f-7d2465f1ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def TransitionTensor(self:UncertainSocialDilemma):\n",
    "        \"\"\"Get the Transition Tensor.\"\"\"\n",
    "        Tsas = np.ones((2, 2, 2, 2)) * (-1)\n",
    "\n",
    "        Tsas[:, :, :, 0] = 1-self.pC\n",
    "        Tsas[:, :, :, 1] = self.pC\n",
    "\n",
    "        return Tsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0a8f3-6a6e-49f7-9d2f-599840485450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def RewardTensor(self:UncertainSocialDilemma):\n",
    "        \"\"\"Get the Reward Tensor R[i,s,a1,...,aN,s'].\"\"\"\n",
    "\n",
    "        R = np.zeros((2, 2, 2, 2, 2))\n",
    "\n",
    "        R[0, 0, :, :, 0] = [[self.R1, self.S1],\n",
    "                            [self.T1, self.P1]]\n",
    "        R[1, 0, :, :, 0] = [[self.R1, self.T1],\n",
    "                            [self.S1, self.P1]]\n",
    "        R[:, 0, :, :, 1] = R[:, 0, :, :, 0]\n",
    "\n",
    "        R[0, 1, :, :, 1] = [[self.R2, self.S2],\n",
    "                            [self.T2, self.P2]]\n",
    "        R[1, 1, :, :, 1] = [[self.R2, self.T2],\n",
    "                            [self.S2, self.P2]]\n",
    "        R[:, 1, :, :, 0] = R[:, 1, :, :, 1]\n",
    "\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8dae38-54f5-4db9-9a3c-c0da488b451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def ObservationTensor(self:UncertainSocialDilemma):\n",
    "\n",
    "        if np.all(self.noise > 0.5):\n",
    "            self.Q = 1\n",
    "            Oiso = np.ones((self.N, self.Z, self.Q))\n",
    "            \n",
    "        else:\n",
    "            self.Q = self.Z\n",
    "            Oiso = np.zeros((self.N, self.Z, self.Q))\n",
    "\n",
    "            for i in range(self.N):\n",
    "                Oiso[i,0,0] = 1 - min(self.noise[i], 0.5)\n",
    "                Oiso[i,0,1] = 0 + min(self.noise[i], 0.5)\n",
    "                Oiso[i,1,0] = 0 + min(self.noise[i], 0.5)\n",
    "                Oiso[i,1,1] = 1 - min(self.noise[i], 0.5)\n",
    "            \n",
    "        return Oiso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e09388-5eaa-46c0-aeec-201f7685620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def id(self:UncertainSocialDilemma):\n",
    "    \"\"\"\n",
    "    Returns id string of environment\n",
    "    \"\"\"\n",
    "    # Default\n",
    "    R1 = self.R1\n",
    "    T1 = self.T1\n",
    "    S1 = self.S1\n",
    "    P1 = self.P1 \n",
    "    R2 = self.R1 \n",
    "    T2 = self.T2\n",
    "    S2 = self.S2\n",
    "    P2 = self.P2 \n",
    "    pC = self.pC \n",
    "    noise = self.noise if len(np.unique(self.noise))>1 else self.noise[0]\n",
    "\n",
    "    id = f\"{self.__class__.__name__}_\"+\\\n",
    "        f\"{self.N}_{str(R1)}_{str(T1)}_{str(S1)}_{str(P1)}_{str(R2)}_{str(T2)}_{str(S2)}_{str(P2)}_{str(pC)}_{str(noise)}\"\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623f2ee-661a-4695-b296-cd937ce3e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
