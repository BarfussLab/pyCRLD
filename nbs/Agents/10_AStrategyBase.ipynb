{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5716763c-7088-4e60-a2b1-88e513c39406",
   "metadata": {},
   "source": [
    "# Strategy Base\n",
    "\n",
    "> Base class containing the core methods of CRLD agents in strategy space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4a756-5910-4410-820f-7021944c9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Agents/StrategyBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ae0a7-f5cb-41d9-bf5e-eba3ea537fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Imports for the nbdev development environment\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8347a3c-6f6b-4a11-9af4-d7ba71bb5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfde18-fe2e-468a-b7cc-e169e3969e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from functools import partial\n",
    "\n",
    "# import jax\n",
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "from typing import Iterable\n",
    "from fastcore.utils import *\n",
    "\n",
    "from pyCRLD.Agents.Base import abase\n",
    "from pyCRLD.Utils.Helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1e885-0eaf-448d-98f9-b106944a90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class strategybase(abase):\n",
    "    \"\"\"\n",
    "    Base class for deterministic strategy-average independent (multi-agent)\n",
    "    temporal-difference reinforcement learning in strategy space.        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 env, # An environment object\n",
    "                 learning_rates:Union[float, Iterable], # agents' learning rates\n",
    "                 discount_factors:Union[float, Iterable], # agents' discount factors\n",
    "                 choice_intensities:Union[float, Iterable]=1.0, # agents' choice intensities\n",
    "                 use_prefactor=False,  # use the 1-DiscountFactor prefactor\n",
    "                 opteinsum=True,  # optimize einsum functions\n",
    "                 **kwargs):\n",
    "\n",
    "        self.env = env\n",
    "        Tt = env.T; assert np.allclose(Tt.sum(-1), 1)\n",
    "        Rt = env.R    \n",
    "        super().__init__(Tt, Rt, discount_factors, use_prefactor, opteinsum)\n",
    "        self.F = jnp.array(env.F)\n",
    "\n",
    "        # learning rates\n",
    "        self.alpha = make_variable_vector(learning_rates, self.N)\n",
    "\n",
    "        # intensity of choice\n",
    "        self.beta = make_variable_vector(choice_intensities, self.N)\n",
    "\n",
    "        \n",
    "        self.TDerror = self.RPEisa\n",
    "        \n",
    "    @partial(jit, static_argnums=0)\n",
    "    def step(self,\n",
    "             Xisa  # Joint strategy\n",
    "            ) -> tuple:  # (Updated joint strategy, Prediction error)\n",
    "        \"\"\"\n",
    "        Performs a learning step along the reward-prediction/temporal-difference error\n",
    "        in strategy space, given joint strategy `Xisa`.\n",
    "        \"\"\"\n",
    "        TDe = self.TDerror(Xisa)\n",
    "        n = jnp.newaxis\n",
    "        XexpaTDe = Xisa * jnp.exp(self.alpha[:,n,n] * TDe)\n",
    "        return XexpaTDe / XexpaTDe.sum(-1, keepdims=True), TDe\n",
    "    \n",
    "    @partial(jit, static_argnums=0)\n",
    "    def reverse_step(self,\n",
    "                    Xisa  # Joint strategy\n",
    "                    ) -> tuple:  # (Updated joint strategy, Prediction error)\n",
    "        \"\"\"\n",
    "        Performs a reverse learning step in strategy space,\n",
    "        given joint strategy `Xisa`.\n",
    "        \n",
    "        This is useful to compute the separatrix of a multistable regime. \n",
    "        \"\"\"\n",
    "        TDe = self.TDerror(Xisa)\n",
    "        n = jnp.newaxis\n",
    "        XexpaTDe = Xisa * jnp.exp(self.alpha[:,n,n] * -TDe)\n",
    "        return XexpaTDe / XexpaTDe.sum(-1, keepdims=True), TDe  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68fd49cb-99b4-4171-a422-9f5526526ceb",
   "metadata": {},
   "source": [
    "Further optional paramerater inherting from `abase`:\n",
    "\n",
    "|  | Type | Default |  Details |\n",
    "| -- | -- | -- | -- |\n",
    "| use_prefactor | bool | False |  use the 1-DiscountFactor prefactor |\n",
    "| opteinsum | bool | True |  optimize einsum functions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be06f3f-2b13-46b8-83f5-322b9a7f20b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/wbarfuss/pyCRLD/blob/main/pyCRLD/Agents/StrategyBase.py#L52){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### strategybase.step\n",
       "\n",
       ">      strategybase.step (Xisa)\n",
       "\n",
       "Performs a learning step along the reward-prediction/temporal-difference error\n",
       "in strategy space, given joint strategy `Xisa`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Xisa |  | Joint strategy |\n",
       "| **Returns** | **tuple** | **(Updated joint strategy, Prediction error)** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/wbarfuss/pyCRLD/blob/main/pyCRLD/Agents/StrategyBase.py#L52){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### strategybase.step\n",
       "\n",
       ">      strategybase.step (Xisa)\n",
       "\n",
       "Performs a learning step along the reward-prediction/temporal-difference error\n",
       "in strategy space, given joint strategy `Xisa`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Xisa |  | Joint strategy |\n",
       "| **Returns** | **tuple** | **(Updated joint strategy, Prediction error)** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(strategybase.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/wbarfuss/pyCRLD/blob/main/pyCRLD/Agents/StrategyBase.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### strategybase.reverse_step\n",
       "\n",
       ">      strategybase.reverse_step (Xisa)\n",
       "\n",
       "Performs a reverse learning step in strategy space,\n",
       "given joint strategy `Xisa`.\n",
       "\n",
       "This is useful to compute the separatrix of a multistable regime.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Xisa |  | Joint strategy |\n",
       "| **Returns** | **tuple** | **(Updated joint strategy, Prediction error)** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/wbarfuss/pyCRLD/blob/main/pyCRLD/Agents/StrategyBase.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### strategybase.reverse_step\n",
       "\n",
       ">      strategybase.reverse_step (Xisa)\n",
       "\n",
       "Performs a reverse learning step in strategy space,\n",
       "given joint strategy `Xisa`.\n",
       "\n",
       "This is useful to compute the separatrix of a multistable regime.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| Xisa |  | Joint strategy |\n",
       "| **Returns** | **tuple** | **(Updated joint strategy, Prediction error)** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(strategybase.reverse_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635fdd7-ef4f-40ae-be4d-94f56e639fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def zero_intelligence_strategy(self:strategybase):\n",
    "    \"\"\"Returns strategy `Xisa` with equal action probabilities.\"\"\"\n",
    "    return jnp.ones((self.N, self.Z, self.M)) / float(self.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aca7b5-dadd-4a65-a327-ff60f04dce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def random_softmax_strategy(self:strategybase):\n",
    "    \"\"\"Returns softmax strategy `Xisa` with random action probabilities.\"\"\"\n",
    "    expQ = np.exp(np.random.randn(self.N, self.Z, self.M))\n",
    "    X = expQ / expQ.sum(axis=-1, keepdims=True)\n",
    "    return jnp.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0d631-44d0-441e-a893-f9d0242e9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def id(self:strategybase\n",
    "      ) -> str:  # id\n",
    "    \"\"\"Returns an identifier to handle simulation runs.\"\"\"\n",
    "    envid = self.env.id() + \"__\"\n",
    "    agentsid = f\"j{self.__class__.__name__}_\"\n",
    "\n",
    "    if hasattr(self, 'O') and hasattr(self, 'Q'):\n",
    "        agentsid += 'PartObs_'        \n",
    "\n",
    "    agentsid += f\"{str(self.alpha)}_{str(self.gamma)}_{str(self.beta)}\"\\\n",
    "        + f\"pre{self.use_prefactor}\"\n",
    "\n",
    "    return envid + agentsid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef36d7-a93d-4530-bf81-4a3f875294bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6974e-255f-4ed6-813b-a88ca1b22c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
